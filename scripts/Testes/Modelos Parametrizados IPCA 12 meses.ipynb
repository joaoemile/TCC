{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "950b8cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 02:13:24,580 - INFO - Carregando dados...\n",
      "2025-05-05 02:13:25,373 - INFO - Preparando dados...\n",
      "2025-05-05 02:13:25,391 - INFO - Tamanho do conjunto de treino: 87 observações\n",
      "2025-05-05 02:13:25,392 - INFO - Tamanho do conjunto de teste: 22 observações\n",
      "2025-05-05 02:13:25,393 - INFO - Otimizando Ridge Regression...\n",
      "2025-05-05 02:13:25,598 - INFO - Melhores parâmetros para Ridge Regression: {'alpha': 0.1}\n",
      "2025-05-05 02:13:25,604 - INFO - Otimizando SVR...\n",
      "2025-05-05 02:13:29,134 - INFO - Melhores parâmetros para SVR: {'C': 0.1, 'degree': 2, 'epsilon': 0.001, 'kernel': 'poly'}\n",
      "2025-05-05 02:13:29,139 - INFO - Otimizando Decision Tree...\n",
      "2025-05-05 02:13:30,370 - INFO - Melhores parâmetros para Decision Tree: {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "2025-05-05 02:13:30,376 - INFO - Otimizando Gradient Boosting...\n",
      "2025-05-05 02:16:02,802 - INFO - Melhores parâmetros para Gradient Boosting: {'learning_rate': 0.2, 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "2025-05-05 02:16:02,806 - INFO - Otimizando Random Forest...\n",
      "C:\\Users\\JoãoEmileXimenesMuri\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\ma\\core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "2025-05-05 02:19:07,639 - INFO - Melhores parâmetros para Random Forest: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Função para calcular o MAPE\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Carregar os dados\n",
    "logging.info(\"Carregando dados...\")\n",
    "data = pd.read_excel(\"C:\\\\Users\\\\JoãoEmileXimenesMuri\\\\Documents\\\\pessoal\\\\TCC\\\\Bases TCC\\\\Dados_TCC_2014_2024_Normalizados_TabUnica.xlsx\")\n",
    "\n",
    "# Preparar os dados\n",
    "logging.info(\"Preparando dados...\")\n",
    "data['IPCA_Next'] = data['Valor IPCA'].shift(-1)\n",
    "data = data.dropna()\n",
    "X = data.drop(columns=['Data Referência', 'Valor IPCA', 'IPCA_Next'])\n",
    "y = data['IPCA_Next']\n",
    "\n",
    "# Divisão treino/teste (80/20, mantendo ordem temporal)\n",
    "train_size = int(len(data) * 0.8)\n",
    "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
    "logging.info(f\"Tamanho do conjunto de treino: {len(X_train)} observações\")\n",
    "logging.info(f\"Tamanho do conjunto de teste: {len(X_test)} observações\")\n",
    "\n",
    "# Definir modelos e grades de hiperparâmetros expandidas\n",
    "models = {\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'SVR': SVR(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Ridge Regression': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]  # Ampliado\n",
    "    },\n",
    "    'SVR': {\n",
    "        'C': [0.01, 0.1, 1.0, 10.0, 100.0],  # Ampliado\n",
    "        'epsilon': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "        'kernel': ['rbf', 'linear', 'poly'],\n",
    "        'degree': [2, 3]  # Para kernel poly\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [5, 6, 7, 8, 9],  # Foco em torno de 7\n",
    "        'min_samples_split': [2, 5, 10, 15],\n",
    "        'min_samples_leaf': [1, 2, 3]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "        'max_depth': [2, 3, 4, 5],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'max_depth': [4, 5, 6, 7, 8],  # Foco em torno de 5\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 3]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Configurar validação cruzada temporal\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Treinar e avaliar modelos com GridSearchCV\n",
    "results = []\n",
    "predictions = {}\n",
    "best_params = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    logging.info(f\"Otimizando {name}...\")\n",
    "    try:\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids[name],\n",
    "            cv=tscv,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=1  # Sem paralelismo para evitar TerminatedWorkerError\n",
    "        )\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Armazenar melhores parâmetros\n",
    "        best_params[name] = grid_search.best_params_\n",
    "        logging.info(f\"Melhores parâmetros para {name}: {best_params[name]}\")\n",
    "        \n",
    "        # Treinar modelo com melhores parâmetros\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Calcular métricas\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'MAPE (%)': mape,\n",
    "            'R2': r2\n",
    "        })\n",
    "        \n",
    "        # Armazenar previsões\n",
    "        predictions[name] = y_pred\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao otimizar {name}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "016d1aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhores Hiperparâmetros:\n",
      "Ridge Regression: {'alpha': 0.1}\n",
      "SVR: {'C': 0.1, 'degree': 2, 'epsilon': 0.001, 'kernel': 'poly'}\n",
      "Decision Tree: {'max_depth': 6, 'min_samples_leaf': 3, 'min_samples_split': 2}\n",
      "Gradient Boosting: {'learning_rate': 0.2, 'max_depth': 3, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Random Forest: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Exibir melhores parâmetros\n",
    "print(\"\\nMelhores Hiperparâmetros:\")\n",
    "for name, params in best_params.items():\n",
    "    print(f\"{name}: {params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9774546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados dos Modelos (com Hiperparâmetros Otimizados):\n",
      "               Model      RMSE       MAE   MAPE (%)        R2\n",
      "0   Ridge Regression  0.254381  0.232763  71.867596  0.063340\n",
      "1                SVR  0.215762  0.180541  51.806877  0.326150\n",
      "2      Decision Tree  0.117584  0.084284  21.679909  0.799871\n",
      "3  Gradient Boosting  0.152836  0.124825  31.870249  0.661884\n",
      "4      Random Forest  0.149297  0.124967  32.492663  0.677361\n"
     ]
    }
   ],
   "source": [
    "# Criar DataFrame com resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nResultados dos Modelos (com Hiperparâmetros Otimizados):\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36bf0420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhor Modelo (baseado no RMSE):\n",
      "Model       Decision Tree\n",
      "RMSE             0.117584\n",
      "MAE              0.084284\n",
      "MAPE (%)        21.679909\n",
      "R2               0.799871\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Identificar o melhor modelo (menor RMSE)\n",
    "if not results_df.empty:\n",
    "    best_model = results_df.loc[results_df['RMSE'].idxmin()]\n",
    "    print(\"\\nMelhor Modelo (baseado no RMSE):\")\n",
    "    print(best_model)\n",
    "else:\n",
    "    print(\"\\nNenhum modelo foi otimizado com sucesso.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
